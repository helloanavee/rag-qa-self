{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b1c72e6f-2f74-41ab-8374-5614a16b9d4d",
   "metadata": {},
   "source": [
    "# RAG-based ANA QNA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6dd4bc31-15ec-4366-836a-affba6d21fda",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\ana\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\ana\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\ana\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\ana\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\ana\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\ana\\anaconda3\\lib\\site-packages)\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade --quiet  gpt4all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5dfbbed1-b232-4d51-8a7b-7ef75e2f0865",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langchain in c:\\users\\ana\\anaconda3\\lib\\site-packages (0.3.7)\n",
      "Requirement already satisfied: pydantic in c:\\users\\ana\\anaconda3\\lib\\site-packages (2.9.2)\n",
      "Requirement already satisfied: PyYAML>=5.3 in c:\\users\\ana\\anaconda3\\lib\\site-packages (from langchain) (6.0)\n",
      "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in c:\\users\\ana\\anaconda3\\lib\\site-packages (from langchain) (4.0.3)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in c:\\users\\ana\\anaconda3\\lib\\site-packages (from langchain) (1.4.39)\n",
      "Requirement already satisfied: langchain-core<0.4.0,>=0.3.15 in c:\\users\\ana\\anaconda3\\lib\\site-packages (from langchain) (0.3.15)\n",
      "Requirement already satisfied: numpy<2,>=1 in c:\\users\\ana\\anaconda3\\lib\\site-packages (from langchain) (1.23.5)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in c:\\users\\ana\\anaconda3\\lib\\site-packages (from langchain) (3.10.10)\n",
      "Requirement already satisfied: langsmith<0.2.0,>=0.1.17 in c:\\users\\ana\\anaconda3\\lib\\site-packages (from langchain) (0.1.142)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in c:\\users\\ana\\anaconda3\\lib\\site-packages (from langchain) (8.5.0)\n",
      "Requirement already satisfied: requests<3,>=2 in c:\\users\\ana\\anaconda3\\lib\\site-packages (from langchain) (2.28.1)\n",
      "Requirement already satisfied: langchain-text-splitters<0.4.0,>=0.3.0 in c:\\users\\ana\\anaconda3\\lib\\site-packages (from langchain) (0.3.2)\n",
      "Requirement already satisfied: pydantic-core==2.23.4 in c:\\users\\ana\\anaconda3\\lib\\site-packages (from pydantic) (2.23.4)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\ana\\anaconda3\\lib\\site-packages (from pydantic) (0.6.0)\n",
      "Requirement already satisfied: typing-extensions>=4.6.1 in c:\\users\\ana\\anaconda3\\lib\\site-packages (from pydantic) (4.12.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.12.0 in c:\\users\\ana\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.17.1)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\ana\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\ana\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.1.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\ana\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\ana\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (22.1.0)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in c:\\users\\ana\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (2.4.3)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in c:\\users\\ana\\anaconda3\\lib\\site-packages (from langchain-core<0.4.0,>=0.3.15->langchain) (1.33)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in c:\\users\\ana\\anaconda3\\lib\\site-packages (from langchain-core<0.4.0,>=0.3.15->langchain) (24.2)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in c:\\users\\ana\\anaconda3\\lib\\site-packages (from langsmith<0.2.0,>=0.1.17->langchain) (1.0.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\users\\ana\\anaconda3\\lib\\site-packages (from langsmith<0.2.0,>=0.1.17->langchain) (0.27.2)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in c:\\users\\ana\\anaconda3\\lib\\site-packages (from langsmith<0.2.0,>=0.1.17->langchain) (3.10.11)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\ana\\anaconda3\\lib\\site-packages (from requests<3,>=2->langchain) (2024.6.2)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\ana\\anaconda3\\lib\\site-packages (from requests<3,>=2->langchain) (1.26.14)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\ana\\anaconda3\\lib\\site-packages (from requests<3,>=2->langchain) (3.4)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in c:\\users\\ana\\anaconda3\\lib\\site-packages (from requests<3,>=2->langchain) (2.1.1)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in c:\\users\\ana\\anaconda3\\lib\\site-packages (from SQLAlchemy<3,>=1.4->langchain) (2.0.1)\n",
      "Requirement already satisfied: sniffio in c:\\users\\ana\\anaconda3\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain) (1.2.0)\n",
      "Requirement already satisfied: anyio in c:\\users\\ana\\anaconda3\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain) (3.5.0)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\ana\\anaconda3\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain) (1.0.6)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\ana\\anaconda3\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain) (0.14.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in c:\\users\\ana\\anaconda3\\lib\\site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.15->langchain) (2.1)\n",
      "Requirement already satisfied: propcache>=0.2.0 in c:\\users\\ana\\anaconda3\\lib\\site-packages (from yarl<2.0,>=1.12.0->aiohttp<4.0.0,>=3.8.3->langchain) (0.2.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\ana\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\ana\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\ana\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\ana\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\ana\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\ana\\anaconda3\\lib\\site-packages)\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade langchain pydantic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cb59ea7a-016f-44d0-a8aa-fef742b3c0b9",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\ana\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\ana\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\ana\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\ana\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\ana\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\ana\\anaconda3\\lib\\site-packages)\n"
     ]
    }
   ],
   "source": [
    "!pip install -q -U google-generativeai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "891daee4-c097-42f2-b689-6a7080ed3953",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting streamlit\n",
      "  Downloading streamlit-1.40.1-py2.py3-none-any.whl (8.6 MB)\n",
      "     ---------------------------------------- 8.6/8.6 MB 6.8 MB/s eta 0:00:00\n",
      "Requirement already satisfied: gitpython!=3.1.19,<4,>=3.0.7 in c:\\users\\ana\\anaconda3\\lib\\site-packages (from streamlit) (3.1.43)\n",
      "Requirement already satisfied: click<9,>=7.0 in c:\\users\\ana\\anaconda3\\lib\\site-packages (from streamlit) (8.0.4)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.3.0 in c:\\users\\ana\\anaconda3\\lib\\site-packages (from streamlit) (4.12.2)\n",
      "Requirement already satisfied: tornado<7,>=6.0.3 in c:\\users\\ana\\anaconda3\\lib\\site-packages (from streamlit) (6.1)\n",
      "Collecting pydeck<1,>=0.8.0b4\n",
      "  Downloading pydeck-0.9.1-py2.py3-none-any.whl (6.9 MB)\n",
      "     ---------------------------------------- 6.9/6.9 MB 6.5 MB/s eta 0:00:00\n",
      "Requirement already satisfied: toml<2,>=0.10.1 in c:\\users\\ana\\anaconda3\\lib\\site-packages (from streamlit) (0.10.2)\n",
      "Requirement already satisfied: pandas<3,>=1.4.0 in c:\\users\\ana\\anaconda3\\lib\\site-packages (from streamlit) (1.5.3)\n",
      "Collecting altair<6,>=4.0\n",
      "  Downloading altair-5.4.1-py3-none-any.whl (658 kB)\n",
      "     ------------------------------------- 658.1/658.1 kB 10.3 MB/s eta 0:00:00\n",
      "Requirement already satisfied: packaging<25,>=20 in c:\\users\\ana\\anaconda3\\lib\\site-packages (from streamlit) (24.2)\n",
      "Requirement already satisfied: tenacity<10,>=8.1.0 in c:\\users\\ana\\anaconda3\\lib\\site-packages (from streamlit) (8.5.0)\n",
      "Collecting blinker<2,>=1.0.0\n",
      "  Downloading blinker-1.9.0-py3-none-any.whl (8.5 kB)\n",
      "Requirement already satisfied: watchdog<7,>=2.1.5 in c:\\users\\ana\\anaconda3\\lib\\site-packages (from streamlit) (2.1.6)\n",
      "Requirement already satisfied: cachetools<6,>=4.0 in c:\\users\\ana\\anaconda3\\lib\\site-packages (from streamlit) (5.3.3)\n",
      "Collecting rich<14,>=10.14.0\n",
      "  Downloading rich-13.9.4-py3-none-any.whl (242 kB)\n",
      "     -------------------------------------- 242.4/242.4 kB 7.5 MB/s eta 0:00:00\n",
      "Requirement already satisfied: numpy<3,>=1.20 in c:\\users\\ana\\anaconda3\\lib\\site-packages (from streamlit) (1.23.5)\n",
      "Requirement already satisfied: protobuf<6,>=3.20 in c:\\users\\ana\\anaconda3\\lib\\site-packages (from streamlit) (4.25.5)\n",
      "Requirement already satisfied: requests<3,>=2.27 in c:\\users\\ana\\anaconda3\\lib\\site-packages (from streamlit) (2.28.1)\n",
      "Requirement already satisfied: pillow<12,>=7.1.0 in c:\\users\\ana\\anaconda3\\lib\\site-packages (from streamlit) (11.0.0)\n",
      "Collecting pyarrow>=7.0\n",
      "  Downloading pyarrow-18.0.0-cp310-cp310-win_amd64.whl (25.1 MB)\n",
      "     ---------------------------------------- 25.1/25.1 MB 5.8 MB/s eta 0:00:00\n",
      "Requirement already satisfied: jinja2 in c:\\users\\ana\\anaconda3\\lib\\site-packages (from altair<6,>=4.0->streamlit) (3.1.2)\n",
      "Collecting narwhals>=1.5.2\n",
      "  Downloading narwhals-1.13.4-py3-none-any.whl (206 kB)\n",
      "     ------------------------------------- 206.3/206.3 kB 12.3 MB/s eta 0:00:00\n",
      "Requirement already satisfied: jsonschema>=3.0 in c:\\users\\ana\\anaconda3\\lib\\site-packages (from altair<6,>=4.0->streamlit) (4.17.3)\n",
      "Requirement already satisfied: colorama in c:\\users\\ana\\anaconda3\\lib\\site-packages (from click<9,>=7.0->streamlit) (0.4.6)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in c:\\users\\ana\\anaconda3\\lib\\site-packages (from gitpython!=3.1.19,<4,>=3.0.7->streamlit) (4.0.11)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in c:\\users\\ana\\anaconda3\\lib\\site-packages (from pandas<3,>=1.4.0->streamlit) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\ana\\anaconda3\\lib\\site-packages (from pandas<3,>=1.4.0->streamlit) (2022.7)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in c:\\users\\ana\\anaconda3\\lib\\site-packages (from requests<3,>=2.27->streamlit) (2.1.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\ana\\anaconda3\\lib\\site-packages (from requests<3,>=2.27->streamlit) (3.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\ana\\anaconda3\\lib\\site-packages (from requests<3,>=2.27->streamlit) (2024.6.2)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\ana\\anaconda3\\lib\\site-packages (from requests<3,>=2.27->streamlit) (1.26.14)\n",
      "Collecting markdown-it-py>=2.2.0\n",
      "  Downloading markdown_it_py-3.0.0-py3-none-any.whl (87 kB)\n",
      "     ---------------------------------------- 87.5/87.5 kB 5.2 MB/s eta 0:00:00\n",
      "Collecting pygments<3.0.0,>=2.13.0\n",
      "  Downloading pygments-2.18.0-py3-none-any.whl (1.2 MB)\n",
      "     ---------------------------------------- 1.2/1.2 MB 9.6 MB/s eta 0:00:00\n",
      "Requirement already satisfied: smmap<6,>=3.0.1 in c:\\users\\ana\\anaconda3\\lib\\site-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.19,<4,>=3.0.7->streamlit) (5.0.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\ana\\anaconda3\\lib\\site-packages (from jinja2->altair<6,>=4.0->streamlit) (2.1.1)\n",
      "Requirement already satisfied: attrs>=17.4.0 in c:\\users\\ana\\anaconda3\\lib\\site-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (22.1.0)\n",
      "Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in c:\\users\\ana\\anaconda3\\lib\\site-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.18.0)\n",
      "Collecting mdurl~=0.1\n",
      "  Downloading mdurl-0.1.2-py3-none-any.whl (10.0 kB)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\ana\\anaconda3\\lib\\site-packages (from python-dateutil>=2.8.1->pandas<3,>=1.4.0->streamlit) (1.16.0)\n",
      "Installing collected packages: pygments, pyarrow, narwhals, mdurl, blinker, pydeck, markdown-it-py, altair, rich, streamlit\n",
      "  Attempting uninstall: pygments\n",
      "    Found existing installation: Pygments 2.11.2\n",
      "    Uninstalling Pygments-2.11.2:\n",
      "      Successfully uninstalled Pygments-2.11.2\n",
      "Successfully installed altair-5.4.1 blinker-1.9.0 markdown-it-py-3.0.0 mdurl-0.1.2 narwhals-1.13.4 pyarrow-18.0.0 pydeck-0.9.1 pygments-2.18.0 rich-13.9.4 streamlit-1.40.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\ana\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\ana\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\ana\\anaconda3\\lib\\site-packages)\n",
      "    WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\ana\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\ana\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\ana\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\ana\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\ana\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\ana\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\ana\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\ana\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\ana\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\ana\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\ana\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\ana\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\ana\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\ana\\anaconda3\\lib\\site-packages)\n"
     ]
    }
   ],
   "source": [
    "!pip install streamlit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "670f30da-6485-4936-801e-f631e8403be2",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'streamlit'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[62], line 13\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mgoogle\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mgenerativeai\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mgenai\u001b[39;00m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangchain\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mchains\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ConversationChain\n\u001b[1;32m---> 13\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mstreamlit\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mst\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'streamlit'"
     ]
    }
   ],
   "source": [
    "from langchain.document_loaders import DirectoryLoader\n",
    "from langchain.schema import Document\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain_community.embeddings import GPT4AllEmbeddings\n",
    "import os\n",
    "import shutil\n",
    "from langchain.evaluation import load_evaluator\n",
    "from pydantic import BaseModel, GetJsonSchemaHandler\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "import google.generativeai as genai\n",
    "from langchain.chains import ConversationChain\n",
    "import streamlit as st"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b29aaf28-776c-41c8-8a83-5a3d75746129",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from langchain.chains.conversation.memory import ConversationBufferMemory\n",
    "from langchain.chains.conversation.memory import ConversationSummaryMemory\n",
    "# from langchain.chains.conversation.memory import ConversationBufferWindowMemory\n",
    "# from langchain.chains.conversation.memory import ConversationSummaryBufferMemory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "755e9f2b-238d-4f49-af28-56a611f313f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning, module=\"langchain\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbfc0c2f-b6df-489a-9ba6-8edb2882e186",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### create chunks from documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a5268d82-e7e7-4b7f-8d8d-9a67ceb4992b",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = \"data_sources\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "53160d13-221e-41ac-a241-7f850b41a7bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_documents():\n",
    "    loader = DirectoryLoader(DATA_PATH, glob=\"*.pdf\")\n",
    "    documents = loader.load()\n",
    "    return documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6ddd05b7-d91a-484b-a31e-d0dea7d20462",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "documents = load_documents()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9da0f8e0-be84-4db5-bc28-1295c2d84daf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_text(documents: list[Document]):\n",
    "    text_splitter = RecursiveCharacterTextSplitter(\n",
    "        chunk_size=300,\n",
    "        chunk_overlap=100,\n",
    "        length_function=len,\n",
    "        add_start_index=True,\n",
    "    )\n",
    "    \n",
    "    chunks = text_splitter.split_documents(documents)\n",
    "    \n",
    "    print(f\"Split {len(documents)} documents into {len(chunks)} chunks.\")\n",
    "    \n",
    "    document = chunks[3]\n",
    "    print(document.page_content)\n",
    "    print(document.metadata)\n",
    "    \n",
    "    return chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "814b795f-2e6c-460a-bd03-a83b6a0cfd42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split 1 documents into 19 chunks.\n",
      "WORK EXPERIENCE\n",
      "\n",
      "DATA SCIENCE CONSULTANT for Silver Linings (Jewelry E-commerce)\n",
      "\n",
      "2024, Jan-Mar\n",
      "\n",
      "Worked closely with stakeholders to assess business use cases and provide data-driven recommendations that identified new revenue opportunities.\n",
      "{'source': 'data_sources\\\\Data Scientist - Ana Vasquez.pdf', 'start_index': 556}\n"
     ]
    }
   ],
   "source": [
    "doc_chunks = split_text(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8a7ffc4e-d7c1-4250-a18d-43d478f62a0d",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': 'data_sources\\\\Data Scientist - Ana Vasquez.pdf', 'start_index': 0}, page_content='ANA VASQUEZ avasquez.msds2024@aim.edu | linkedin.com/in/ana-p-vasquez\\n\\ngithub.com/helloanavee | +63 919 001 5061'),\n",
       " Document(metadata={'source': 'data_sources\\\\Data Scientist - Ana Vasquez.pdf', 'start_index': 114}, page_content='With over 5 years of experience as a data scientist, analyst, and software engineer, I specialize in partnering with stakeholders to define and deliver data-driven solutions that drive cost savings and revenue growth. Skilled in both client management and technical tools such as Python and SQL, I'),\n",
       " Document(metadata={'source': 'data_sources\\\\Data Scientist - Ana Vasquez.pdf', 'start_index': 312}, page_content='and revenue growth. Skilled in both client management and technical tools such as Python and SQL, I excel at translating business needs into actionable insights. I am eager to contribute my expertise to support company success and innovation.'),\n",
       " Document(metadata={'source': 'data_sources\\\\Data Scientist - Ana Vasquez.pdf', 'start_index': 556}, page_content='WORK EXPERIENCE\\n\\nDATA SCIENCE CONSULTANT for Silver Linings (Jewelry E-commerce)\\n\\n2024, Jan-Mar\\n\\nWorked closely with stakeholders to assess business use cases and provide data-driven recommendations that identified new revenue opportunities.'),\n",
       " Document(metadata={'source': 'data_sources\\\\Data Scientist - Ana Vasquez.pdf', 'start_index': 799}, page_content='Applied statistical analysis and visualization techniques to uncover historical sales trends and product seasonality, using 4 years of sales data with over 7,000 transactions.\\n\\nUtilized Frequent Itemset Mining to develop product bundling strategies, directly increasing revenue by Php 250,000.00'),\n",
       " Document(metadata={'source': 'data_sources\\\\Data Scientist - Ana Vasquez.pdf', 'start_index': 1096}, page_content='DATA SCIENCE CONSULTANT for Confidential Construction Company\\n\\n2024, Apr-Sept\\n\\nPartnered with cross-functional stakeholders to define business problems and develop data-driven solutions for production, operations, and logistics use cases.'),\n",
       " Document(metadata={'source': 'data_sources\\\\Data Scientist - Ana Vasquez.pdf', 'start_index': 1336}, page_content='Automated data pipelines, improving efficiency by reducing processing time from 3 days to minutes. ● Applied advanced Machine Learning algorithms, including Random Forest, to predict optimal departure times, reducing delivery delays and increasing revenue by Php 112 million annually.'),\n",
       " Document(metadata={'source': 'data_sources\\\\Data Scientist - Ana Vasquez.pdf', 'start_index': 1622}, page_content='Developed and tracked KPIs with the dynamic Power BI dashboard, which reduced trip times by an average of 27 hours per day, leading to fuel cost savings of Php 1.8 million annually.\\n\\nDATA SCIENCE CONSULTANT for Confidential Financial Services\\n\\n2024, Aug-Sept'),\n",
       " Document(metadata={'source': 'data_sources\\\\Data Scientist - Ana Vasquez.pdf', 'start_index': 1805}, page_content='DATA SCIENCE CONSULTANT for Confidential Financial Services\\n\\n2024, Aug-Sept\\n\\nApplied NLP algorithms such as topic modeling to analyze multi-language customer feedback transcripts, improving insights related to payments and financial services.'),\n",
       " Document(metadata={'source': 'data_sources\\\\Data Scientist - Ana Vasquez.pdf', 'start_index': 2049}, page_content='Utilized text classification and clustering techniques on user profiles to improve retention strategies and product ideation.\\n\\nDATA ANALYST for Data Studio Whiz (Data Services and Consultancy)\\n\\n2022 – 2023'),\n",
       " Document(metadata={'source': 'data_sources\\\\Data Scientist - Ana Vasquez.pdf', 'start_index': 2176}, page_content='DATA ANALYST for Data Studio Whiz (Data Services and Consultancy)\\n\\n2022 – 2023\\n\\nLed the development of marketing analytics tools like the Google Analytics dashboard templates, reducing manual work by 240 hours per year resulting in savings of Php 44,880 annually.'),\n",
       " Document(metadata={'source': 'data_sources\\\\Data Scientist - Ana Vasquez.pdf', 'start_index': 2441}, page_content='Collaborated with clients to create end-to-end data projects with SQL and Looker Studio to analyze their data, bringing data-driven insights into the industries of marketing, HR, real estate, health, and finance.\\n\\nDATA ANALYST for The Freelance Movement Tribe (E-Learning Platform)\\n\\n2021 – 2022'),\n",
       " Document(metadata={'source': 'data_sources\\\\Data Scientist - Ana Vasquez.pdf', 'start_index': 2655}, page_content='DATA ANALYST for The Freelance Movement Tribe (E-Learning Platform)\\n\\n2021 – 2022\\n\\nIncreased class attendance by 300%, from 200 to 800 students per session, through data analysis of student feedback and close collaboration with the coaching and product teams.'),\n",
       " Document(metadata={'source': 'data_sources\\\\Data Scientist - Ana Vasquez.pdf', 'start_index': 2915}, page_content='Coordinated with marketing, operations, and product teams to develop programs that improved user retention and increased customer acquisition by 20%, through analysis of 5,000+ member feedback.\\n\\nSOFTWARE ENGINEER for Magis Solutions (Software Development)\\n\\n2017 – 2020'),\n",
       " Document(metadata={'source': 'data_sources\\\\Data Scientist - Ana Vasquez.pdf', 'start_index': 3110}, page_content='SOFTWARE ENGINEER for Magis Solutions (Software Development)\\n\\n2017 – 2020\\n\\nManaged a team of 3 developers to develop scalable web applications in the industries of e-commerce, finance, human resources, and tech.'),\n",
       " Document(metadata={'source': 'data_sources\\\\Data Scientist - Ana Vasquez.pdf', 'start_index': 3323}, page_content='Utilized SQL and PHP to develop programs while maintaining code quality through regular code reviews.\\n\\nEDUCATION'),\n",
       " Document(metadata={'source': 'data_sources\\\\Data Scientist - Ana Vasquez.pdf', 'start_index': 3437}, page_content='Asian Institute of Management Master of Science in Data Science | Dean’s List (2024) De La Salle University Bachelor of Psychology SKILLS: Python, SQL, Power BI, Data Visualization, Stakeholder Management, Sentiment Analysis, NLP, SpaCy, BERT, Hugging Face, Text Classification, TensorFlow, PyTorch,'),\n",
       " Document(metadata={'source': 'data_sources\\\\Data Scientist - Ana Vasquez.pdf', 'start_index': 3643}, page_content='Sentiment Analysis, NLP, SpaCy, BERT, Hugging Face, Text Classification, TensorFlow, PyTorch, Keras, Product Optimization, Search Algorithms, Web Scraping, API Integration, Data Wrangling, Data Mining, Big Data, Cloud Services, Amazon Web Services'),\n",
       " Document(metadata={'source': 'data_sources\\\\Data Scientist - Ana Vasquez.pdf', 'start_index': 3892}, page_content='2023 – 2024\\n\\n2010 – 2013')]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc_chunks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fff7faaa-a3dd-4a79-993e-e69496ec08b9",
   "metadata": {
    "tags": []
   },
   "source": [
    "### save chunks to vector database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "58a11a09-8abb-4ec2-bd52-88ed61886491",
   "metadata": {},
   "outputs": [],
   "source": [
    "CHROMA_PATH = \"chroma\"\n",
    "\n",
    "model_name = \"all-MiniLM-L6-v2.gguf2.f16.gguf\"\n",
    "gpt4all_kwargs = {'allow_download': 'True'}\n",
    "gpt4all_embeddings = GPT4AllEmbeddings(\n",
    "    model_name=model_name,\n",
    "    gpt4all_kwargs=gpt4all_kwargs\n",
    ")\n",
    "    \n",
    "def save_to_chroma(chunks: list[Document]):\n",
    "    # clear previous db\n",
    "    if os.path.exists(CHROMA_PATH):\n",
    "        shutil.rmtree(CHROMA_PATH)\n",
    "\n",
    "    # create db\n",
    "    db = Chroma.from_documents(\n",
    "        doc_chunks, gpt4all_embeddings, persist_directory=CHROMA_PATH\n",
    "    )\n",
    "    \n",
    "    print(f\"Saved {len(chunks)} chunks to {CHROMA_PATH}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e6574c20-e703-4246-890c-c51cb87d75d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved 19 chunks to chroma.\n"
     ]
    }
   ],
   "source": [
    "save_to_chroma(doc_chunks)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34e45e86-40dc-49ab-9d47-cf31cd996654",
   "metadata": {
    "tags": []
   },
   "source": [
    "### query the closest texts from the db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a1d51b6d-5a5e-48b5-952e-451a49f75add",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ana\\AppData\\Local\\Temp\\ipykernel_10072\\4085332997.py:10: LangChainDeprecationWarning: The class `Chroma` was deprecated in LangChain 0.2.9 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-chroma package and should be used instead. To use it run `pip install -U :class:`~langchain-chroma` and import as `from :class:`~langchain_chroma import Chroma``.\n",
      "  db = Chroma(persist_directory=CHROMA_PATH,\n"
     ]
    }
   ],
   "source": [
    "# use the same embedding function\n",
    "model_name = \"all-MiniLM-L6-v2.gguf2.f16.gguf\"\n",
    "gpt4all_kwargs = {'allow_download': 'True'}\n",
    "gpt4all_embeddings = GPT4AllEmbeddings(\n",
    "    model_name=model_name,\n",
    "    gpt4all_kwargs=gpt4all_kwargs\n",
    ")\n",
    "\n",
    "# prepare the db\n",
    "db = Chroma(persist_directory=CHROMA_PATH,\n",
    "            embedding_function=gpt4all_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2ac49c90-fef0-4d8d-b266-231867278388",
   "metadata": {},
   "outputs": [],
   "source": [
    "query_text = \"should i hire her as a data scientist?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "87908381-f339-4a71-a442-cc3661db384a",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = db.similarity_search_with_relevance_scores(query_text, k=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7ab5a3bb-71a6-46d0-af1b-014164e2956f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(Document(metadata={'source': 'data_sources\\\\Data Scientist - Ana Vasquez.pdf', 'start_index': 2441}, page_content='Collaborated with clients to create end-to-end data projects with SQL and Looker Studio to analyze their data, bringing data-driven insights into the industries of marketing, HR, real estate, health, and finance.\\n\\nDATA ANALYST for The Freelance Movement Tribe (E-Learning Platform)\\n\\n2021 – 2022'),\n",
       "  0.18785726628411736),\n",
       " (Document(metadata={'source': 'data_sources\\\\Data Scientist - Ana Vasquez.pdf', 'start_index': 556}, page_content='WORK EXPERIENCE\\n\\nDATA SCIENCE CONSULTANT for Silver Linings (Jewelry E-commerce)\\n\\n2024, Jan-Mar\\n\\nWorked closely with stakeholders to assess business use cases and provide data-driven recommendations that identified new revenue opportunities.'),\n",
       "  0.16815025131821992),\n",
       " (Document(metadata={'source': 'data_sources\\\\Data Scientist - Ana Vasquez.pdf', 'start_index': 1096}, page_content='DATA SCIENCE CONSULTANT for Confidential Construction Company\\n\\n2024, Apr-Sept\\n\\nPartnered with cross-functional stakeholders to define business problems and develop data-driven solutions for production, operations, and logistics use cases.'),\n",
       "  0.16608039985031642)]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4b9ce14-0986-423a-8dc2-7941b026af09",
   "metadata": {
    "tags": []
   },
   "source": [
    "### create the prompt with my custom data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "1b51d1d9-5878-4707-8d51-4939e464a43b",
   "metadata": {},
   "outputs": [],
   "source": [
    "PROMPT_TEMPLATE = \"\"\"\n",
    "Given the following context and a question, generate an answer based on this context only.\n",
    "If the answer is not found in the context, kindly state \"I don't know.\" Don't try to make up an answer.\n",
    "\n",
    "CONTEXT: {context}\n",
    "\n",
    "QUESTION: {question}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "a43c88e0-f9a5-4a30-a40e-6863306ff520",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PROMPT_TEMPLATE = \"\"\"\n",
    "# Answer the question based only on the following context:\n",
    "\n",
    "# {context}\n",
    "\n",
    "# ---\n",
    "\n",
    "# Answer the question based on the above context: {question}\n",
    "# \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "43fd8ba3-c1ae-40ce-88a0-cc38c5522aa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "context_text = \"\\n\\n---\\n\\n\".join([doc.page_content for doc, _score in results])\n",
    "prompt_template = ChatPromptTemplate.from_template(PROMPT_TEMPLATE)\n",
    "prompt = prompt_template.format(context=context_text, question=query_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ba69b435-f0bd-4477-86c0-ecf890ef9332",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Human: \n",
      "Answer the question based only on the following context:\n",
      "\n",
      "Collaborated with clients to create end-to-end data projects with SQL and Looker Studio to analyze their data, bringing data-driven insights into the industries of marketing, HR, real estate, health, and finance.\n",
      "\n",
      "DATA ANALYST for The Freelance Movement Tribe (E-Learning Platform)\n",
      "\n",
      "2021 – 2022\n",
      "\n",
      "---\n",
      "\n",
      "WORK EXPERIENCE\n",
      "\n",
      "DATA SCIENCE CONSULTANT for Silver Linings (Jewelry E-commerce)\n",
      "\n",
      "2024, Jan-Mar\n",
      "\n",
      "Worked closely with stakeholders to assess business use cases and provide data-driven recommendations that identified new revenue opportunities.\n",
      "\n",
      "---\n",
      "\n",
      "DATA SCIENCE CONSULTANT for Confidential Construction Company\n",
      "\n",
      "2024, Apr-Sept\n",
      "\n",
      "Partnered with cross-functional stakeholders to define business problems and develop data-driven solutions for production, operations, and logistics use cases.\n",
      "\n",
      "---\n",
      "\n",
      "Answer the question based on the above context: should i hire her as a data scientist?\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a00e424-c7b3-4e7f-b606-f508b5dd32c2",
   "metadata": {
    "tags": []
   },
   "source": [
    "### prompt the LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d4f2149e-d823-4ae9-823f-86450f82db42",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('GEMINI_KEY.txt', 'r') as file:\n",
    "    exec(file.read().strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "deffac7d-ceba-4e93-ab27-935f59b6c596",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Based on the provided context, it's difficult to definitively say whether you should hire her as a data scientist. Here's why:\n",
      "\n",
      "**Pros:**\n",
      "\n",
      "* **Experience in various industries:** She has worked with data in a variety of fields, showing adaptability and potentially a broader understanding of business needs.\n",
      "* **Data analysis skills:** She demonstrates proficiency in SQL and Looker Studio, indicating solid data analysis skills.\n",
      "* **Collaborative approach:** She highlights working closely with clients and stakeholders, implying good communication and teamwork abilities.\n",
      "* **Data-driven problem solving:**  Her experience with identifying business use cases and providing data-driven recommendations suggests a focus on practical application of data.\n",
      "\n",
      "**Cons:**\n",
      "\n",
      "* **Limited experience in data science:** While she has worked as a \"data science consultant\", the provided context doesn't clearly highlight specific data science skills like machine learning, statistical modeling, or advanced data visualization. \n",
      "* **Short tenure in data science roles:** Her experience in data science roles is relatively short. It's unclear how deeply she has been involved in complex data science projects.\n",
      "* **Lack of specifics:** The context doesn't provide concrete examples of her work or the impact of her data-driven solutions.\n",
      "\n",
      "**Recommendation:**\n",
      "\n",
      "You should gather more information before making a decision.  Ask for:\n",
      "\n",
      "* **Specific projects and accomplishments:**  Request examples of projects she has worked on, the specific data science tools and techniques used, and the impact of her work. \n",
      "* **Technical skills and experience:** Ask about her experience with specific data science methodologies, machine learning algorithms, and other relevant technical skills. \n",
      "* **References:**  Request references from previous employers to get a more comprehensive understanding of her abilities and work style.\n",
      "\n",
      "Based on the additional information you gather, you can make a more informed decision about whether to hire her as a data scientist. \n",
      "\n"
     ]
    }
   ],
   "source": [
    "genai.configure(api_key=API_KEY)\n",
    "model = genai.GenerativeModel(\"gemini-1.5-flash\")\n",
    "response = model.generate_content(prompt)\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "98323117-11c9-491a-af8d-8fa6927daa10",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\ana\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\ana\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\ana\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\ana\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\ana\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\ana\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\ana\\anaconda3\\lib\\site-packages)\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade --quiet  langchain-google-genai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0b30d2f1-30a8-4881-ad63-23d49074d725",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_google_genai import ChatGoogleGenerativeAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "52d82604-27ed-4959-978e-946a33b7a468",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatGoogleGenerativeAI(model=\"gemini-1.5-flash\", google_api_key=API_KEY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "9df445d9-6146-43f7-bcea-b9256ff23382",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = llm.invoke(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "d12f6744-222c-4421-b938-05a8c8054517",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Based on the provided context, it's difficult to definitively say whether you should hire this person as a data scientist. Here's why:\n",
      "\n",
      "**Pros:**\n",
      "\n",
      "* **Experience with SQL and Looker Studio:**  These are valuable tools for data analysis.\n",
      "* **Diverse Industry Experience:** Working in marketing, HR, real estate, health, and finance demonstrates adaptability and a broad understanding of different data landscapes.\n",
      "* **Collaboration and Communication Skills:**  The context highlights working with clients and stakeholders, suggesting strong communication and collaboration abilities.\n",
      "* **Data-Driven Recommendations and Solutions:** The descriptions emphasize the ability to provide insights and solutions based on data analysis.\n",
      "\n",
      "**Cons:**\n",
      "\n",
      "* **Limited Time in Data Science Roles:** The provided information suggests the candidate has primarily worked in data analysis roles, not specifically data science. The data science consultant positions were short-term (3 months and 6 months).\n",
      "* **Lack of Specific Data Science Skills:** The context doesn't mention specific data science techniques like machine learning, statistical modeling, or advanced data visualization. \n",
      "\n",
      "**Recommendation:**\n",
      "\n",
      "To make an informed decision, you should:\n",
      "\n",
      "* **Ask for more details about their data science projects:**  Inquire about the specific data science techniques they used, the complexity of the projects, and the impact of their work.\n",
      "* **Review their resume and portfolio:** This will provide a more comprehensive picture of their skills and experience.\n",
      "* **Conduct an interview:**  Ask targeted questions to assess their technical skills, problem-solving abilities, and understanding of data science concepts.\n",
      "\n",
      "While the candidate has a solid foundation in data analysis, further investigation is needed to determine their suitability for a data scientist role. \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(result.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "8e3e60af-cf89-4c23-b20a-3ea5703a72c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ana\\AppData\\Local\\Temp\\ipykernel_10072\\3865924100.py:1: LangChainDeprecationWarning: The class `ConversationChain` was deprecated in LangChain 0.2.7 and will be removed in 1.0. Use :meth:`~RunnableWithMessageHistory: https://python.langchain.com/v0.2/api_reference/core/runnables/langchain_core.runnables.history.RunnableWithMessageHistory.html` instead.\n",
      "  conversation_with_summary = ConversationChain(\n"
     ]
    }
   ],
   "source": [
    "conversation_with_summary = ConversationChain(\n",
    "    llm=llm,\n",
    "    memory=ConversationSummaryMemory(llm=llm),\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "b1cab2a8-61a2-494a-b72b-ae73f72333c3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "The human asks if they should hire a person as a data scientist based on their provided work experience. The AI states that it's difficult to make a decision based on the provided information because it lacks details about their specific data science skills, qualifications, and accomplishments. The AI suggests gathering more information about their skills, projects, education, and references before making a hiring decision. \n",
      "\n",
      "Human: response:\n",
      "GenerateContentResponse(\n",
      "    done=True,\n",
      "    iterator=None,\n",
      "    result=protos.GenerateContentResponse({\n",
      "      \"candidates\": [\n",
      "        {\n",
      "          \"content\": {\n",
      "            \"parts\": [\n",
      "              {\n",
      "                \"text\": \"Based on the provided context, it's difficult to definitively say whether you should hire her as a data scientist. Here's why:\\n\\n**Pros:**\\n\\n* **Experience in various industries:** She has worked with data in a variety of fields, showing adaptability and potentially a broader understanding of business needs.\\n* **Data analysis skills:** She demonstrates proficiency in SQL and Looker Studio, indicating solid data analysis skills.\\n* **Collaborative approach:** She highlights working closely with clients and stakeholders, implying good communication and teamwork abilities.\\n* **Data-driven problem solving:**  Her experience with identifying business use cases and providing data-driven recommendations suggests a focus on practical application of data.\\n\\n**Cons:**\\n\\n* **Limited experience in data science:** While she has worked as a \\\"data science consultant\\\", the provided context doesn't clearly highlight specific data science skills like machine learning, statistical modeling, or advanced data visualization. \\n* **Short tenure in data science roles:** Her experience in data science roles is relatively short. It's unclear how deeply she has been involved in complex data science projects.\\n* **Lack of specifics:** The context doesn't provide concrete examples of her work or the impact of her data-driven solutions.\\n\\n**Recommendation:**\\n\\nYou should gather more information before making a decision.  Ask for:\\n\\n* **Specific projects and accomplishments:**  Request examples of projects she has worked on, the specific data science tools and techniques used, and the impact of her work. \\n* **Technical skills and experience:** Ask about her experience with specific data science methodologies, machine learning algorithms, and other relevant technical skills. \\n* **References:**  Request references from previous employers to get a more comprehensive understanding of her abilities and work style.\\n\\nBased on the additional information you gather, you can make a more informed decision about whether to hire her as a data scientist. \\n\"\n",
      "              }\n",
      "            ],\n",
      "            \"role\": \"model\"\n",
      "          },\n",
      "          \"finish_reason\": \"STOP\",\n",
      "          \"index\": 0,\n",
      "          \"safety_ratings\": [\n",
      "            {\n",
      "              \"category\": \"HARM_CATEGORY_SEXUALLY_EXPLICIT\",\n",
      "              \"probability\": \"NEGLIGIBLE\"\n",
      "            },\n",
      "            {\n",
      "              \"category\": \"HARM_CATEGORY_HATE_SPEECH\",\n",
      "              \"probability\": \"NEGLIGIBLE\"\n",
      "            },\n",
      "            {\n",
      "              \"category\": \"HARM_CATEGORY_HARASSMENT\",\n",
      "              \"probability\": \"NEGLIGIBLE\"\n",
      "            },\n",
      "            {\n",
      "              \"category\": \"HARM_CATEGORY_DANGEROUS_CONTENT\",\n",
      "              \"probability\": \"NEGLIGIBLE\"\n",
      "            }\n",
      "          ]\n",
      "        }\n",
      "      ],\n",
      "      \"usage_metadata\": {\n",
      "        \"prompt_token_count\": 208,\n",
      "        \"candidates_token_count\": 385,\n",
      "        \"total_token_count\": 593\n",
      "      }\n",
      "    }),\n",
      ")\n",
      "AI:\u001b[0m\n"
     ]
    },
    {
     "ename": "ValidationError",
     "evalue": "3 validation errors for HumanMessage\ncontent.str\n  Input should be a valid string [type=string_type, input_value=response:\nGenerateContent...\": 593\n      }\n    }),\n), input_type=GenerateContentResponse]\n    For further information visit https://errors.pydantic.dev/2.9/v/string_type\ncontent.list[union[str,dict[any,any]]].0.str\n  Input should be a valid string [type=string_type, input_value=response:\nGenerateContent...\": 593\n      }\n    }),\n), input_type=GenerateContentResponse]\n    For further information visit https://errors.pydantic.dev/2.9/v/string_type\ncontent.list[union[str,dict[any,any]]].0.dict[any,any]\n  Input should be a valid dictionary [type=dict_type, input_value=response:\nGenerateContent...\": 593\n      }\n    }),\n), input_type=GenerateContentResponse]\n    For further information visit https://errors.pydantic.dev/2.9/v/dict_type",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValidationError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[45], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m response_with_summary \u001b[38;5;241m=\u001b[39m \u001b[43mconversation_with_summary\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\langchain\\chains\\base.py:170\u001b[0m, in \u001b[0;36mChain.invoke\u001b[1;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[0;32m    168\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    169\u001b[0m     run_manager\u001b[38;5;241m.\u001b[39mon_chain_error(e)\n\u001b[1;32m--> 170\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[0;32m    171\u001b[0m run_manager\u001b[38;5;241m.\u001b[39mon_chain_end(outputs)\n\u001b[0;32m    173\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m include_run_info:\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\langchain\\chains\\base.py:165\u001b[0m, in \u001b[0;36mChain.invoke\u001b[1;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[0;32m    158\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_inputs(inputs)\n\u001b[0;32m    159\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    160\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call(inputs, run_manager\u001b[38;5;241m=\u001b[39mrun_manager)\n\u001b[0;32m    161\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m new_arg_supported\n\u001b[0;32m    162\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call(inputs)\n\u001b[0;32m    163\u001b[0m     )\n\u001b[1;32m--> 165\u001b[0m     final_outputs: Dict[\u001b[38;5;28mstr\u001b[39m, Any] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprep_outputs\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    166\u001b[0m \u001b[43m        \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_only_outputs\u001b[49m\n\u001b[0;32m    167\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    168\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    169\u001b[0m     run_manager\u001b[38;5;241m.\u001b[39mon_chain_error(e)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\langchain\\chains\\base.py:466\u001b[0m, in \u001b[0;36mChain.prep_outputs\u001b[1;34m(self, inputs, outputs, return_only_outputs)\u001b[0m\n\u001b[0;32m    464\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_outputs(outputs)\n\u001b[0;32m    465\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmemory \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 466\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmemory\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave_context\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    467\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m return_only_outputs:\n\u001b[0;32m    468\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m outputs\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\langchain\\memory\\summary.py:125\u001b[0m, in \u001b[0;36mConversationSummaryMemory.save_context\u001b[1;34m(self, inputs, outputs)\u001b[0m\n\u001b[0;32m    123\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msave_context\u001b[39m(\u001b[38;5;28mself\u001b[39m, inputs: Dict[\u001b[38;5;28mstr\u001b[39m, Any], outputs: Dict[\u001b[38;5;28mstr\u001b[39m, \u001b[38;5;28mstr\u001b[39m]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    124\u001b[0m     \u001b[38;5;124;03m\"\"\"Save context from this conversation to buffer.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 125\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave_context\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    126\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbuffer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpredict_new_summary(\n\u001b[0;32m    127\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchat_memory\u001b[38;5;241m.\u001b[39mmessages[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m2\u001b[39m:], \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbuffer\n\u001b[0;32m    128\u001b[0m     )\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\langchain\\memory\\chat_memory.py:74\u001b[0m, in \u001b[0;36mBaseChatMemory.save_context\u001b[1;34m(self, inputs, outputs)\u001b[0m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;124;03m\"\"\"Save context from this conversation to buffer.\"\"\"\u001b[39;00m\n\u001b[0;32m     72\u001b[0m input_str, output_str \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_input_output(inputs, outputs)\n\u001b[0;32m     73\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchat_memory\u001b[38;5;241m.\u001b[39madd_messages(\n\u001b[1;32m---> 74\u001b[0m     [\u001b[43mHumanMessage\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcontent\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_str\u001b[49m\u001b[43m)\u001b[49m, AIMessage(content\u001b[38;5;241m=\u001b[39moutput_str)]\n\u001b[0;32m     75\u001b[0m )\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\langchain_core\\messages\\human.py:56\u001b[0m, in \u001b[0;36mHumanMessage.__init__\u001b[1;34m(self, content, **kwargs)\u001b[0m\n\u001b[0;32m     47\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\n\u001b[0;32m     48\u001b[0m     \u001b[38;5;28mself\u001b[39m, content: Union[\u001b[38;5;28mstr\u001b[39m, \u001b[38;5;28mlist\u001b[39m[Union[\u001b[38;5;28mstr\u001b[39m, \u001b[38;5;28mdict\u001b[39m]]], \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any\n\u001b[0;32m     49\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m     50\u001b[0m     \u001b[38;5;124;03m\"\"\"Pass in content as positional arg.\u001b[39;00m\n\u001b[0;32m     51\u001b[0m \n\u001b[0;32m     52\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[0;32m     53\u001b[0m \u001b[38;5;124;03m        content: The string contents of the message.\u001b[39;00m\n\u001b[0;32m     54\u001b[0m \u001b[38;5;124;03m        kwargs: Additional fields to pass to the message.\u001b[39;00m\n\u001b[0;32m     55\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m---> 56\u001b[0m     \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(content\u001b[38;5;241m=\u001b[39mcontent, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\langchain_core\\messages\\base.py:76\u001b[0m, in \u001b[0;36mBaseMessage.__init__\u001b[1;34m(self, content, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\n\u001b[0;32m     68\u001b[0m     \u001b[38;5;28mself\u001b[39m, content: Union[\u001b[38;5;28mstr\u001b[39m, \u001b[38;5;28mlist\u001b[39m[Union[\u001b[38;5;28mstr\u001b[39m, \u001b[38;5;28mdict\u001b[39m]]], \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any\n\u001b[0;32m     69\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m     70\u001b[0m     \u001b[38;5;124;03m\"\"\"Pass in content as positional arg.\u001b[39;00m\n\u001b[0;32m     71\u001b[0m \n\u001b[0;32m     72\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[0;32m     73\u001b[0m \u001b[38;5;124;03m        content: The string contents of the message.\u001b[39;00m\n\u001b[0;32m     74\u001b[0m \u001b[38;5;124;03m        kwargs: Additional fields to pass to the\u001b[39;00m\n\u001b[0;32m     75\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m---> 76\u001b[0m     \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(content\u001b[38;5;241m=\u001b[39mcontent, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\langchain_core\\load\\serializable.py:125\u001b[0m, in \u001b[0;36mSerializable.__init__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    123\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs: Any, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    124\u001b[0m     \u001b[38;5;124;03m\"\"\"\"\"\"\u001b[39;00m\n\u001b[1;32m--> 125\u001b[0m     \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pydantic\\main.py:212\u001b[0m, in \u001b[0;36mBaseModel.__init__\u001b[1;34m(self, **data)\u001b[0m\n\u001b[0;32m    210\u001b[0m \u001b[38;5;66;03m# `__tracebackhide__` tells pytest and some other tools to omit this function from tracebacks\u001b[39;00m\n\u001b[0;32m    211\u001b[0m __tracebackhide__ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m--> 212\u001b[0m validated_self \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__pydantic_validator__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalidate_python\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mself_instance\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    213\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m validated_self:\n\u001b[0;32m    214\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m    215\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mA custom validator is returning a value other than `self`.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m    216\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mReturning anything other than `self` from a top level model validator isn\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt supported when validating via `__init__`.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    217\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSee the `model_validator` docs (https://docs.pydantic.dev/latest/concepts/validators/#model-validators) for more details.\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m    218\u001b[0m         category\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    219\u001b[0m     )\n",
      "\u001b[1;31mValidationError\u001b[0m: 3 validation errors for HumanMessage\ncontent.str\n  Input should be a valid string [type=string_type, input_value=response:\nGenerateContent...\": 593\n      }\n    }),\n), input_type=GenerateContentResponse]\n    For further information visit https://errors.pydantic.dev/2.9/v/string_type\ncontent.list[union[str,dict[any,any]]].0.str\n  Input should be a valid string [type=string_type, input_value=response:\nGenerateContent...\": 593\n      }\n    }),\n), input_type=GenerateContentResponse]\n    For further information visit https://errors.pydantic.dev/2.9/v/string_type\ncontent.list[union[str,dict[any,any]]].0.dict[any,any]\n  Input should be a valid dictionary [type=dict_type, input_value=response:\nGenerateContent...\": 593\n      }\n    }),\n), input_type=GenerateContentResponse]\n    For further information visit https://errors.pydantic.dev/2.9/v/dict_type"
     ]
    }
   ],
   "source": [
    "response_with_summary = conversation_with_summary.invoke(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba923a06-70bd-4da7-a1ab-de4687baca9e",
   "metadata": {},
   "source": [
    "### prompt with history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "f2e38612-e5fd-441a-81af-89db2a74c409",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from langchain_openai import ChatOpenAI\n",
    "# llm = ChatOpenAI(openai_api_key=openai_api_key)\n",
    "\n",
    "# convert the output of the chatmodel into pure text\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "output_parser = StrOutputParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "e97aa0cd-052d-469d-8c64-8b81b4ebde8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# retriever takes the question then compares with numeric vectors in the db and return the similar text\n",
    "retriever = db.as_retriever()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "398fc7bc-e224-4f20-8ce6-bbd56f03f30b",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\ana\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\ana\\anaconda3\\lib\\site-packages)\n",
      "ERROR: Could not find a version that satisfies the requirement langchain-core-prompts (from versions: none)\n",
      "ERROR: No matching distribution found for langchain-core-prompts\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\ana\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\ana\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\ana\\anaconda3\\lib\\site-packages)\n"
     ]
    }
   ],
   "source": [
    "!pip install langchain-core"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "7d75cb04-6333-46a0-9cd7-53bac2c802d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "\n",
    "instruction_to_system = \"\"\"\n",
    "Given a chat history and the latest user question\n",
    "which might reference context in the chat history, formulate a standalone question\n",
    "which can be understood without the chat history. Do NOT answer the question,\n",
    "just reformulate it if needed and otherwise return it as is.\n",
    "\"\"\"\n",
    "\n",
    "question_maker_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", instruction_to_system),\n",
    "        MessagesPlaceholder(variable_name=\"chat_history\"),\n",
    "        (\"human\", \"{question}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "question_chain = question_maker_prompt | llm | StrOutputParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a6a8cea-9199-40cc-9768-822b373fdedb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
